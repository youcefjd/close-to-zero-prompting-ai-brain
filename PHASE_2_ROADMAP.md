# Phase 2: Incremental Improvement Roadmap

**Status:** âœ… Phase 1 Complete - ai-brain NOW WORKS!
**Date:** 2026-01-08
**Strategy:** Hybrid approach - ship working core, add features incrementally

---

## Phase 1 Complete! âœ…

### What We Just Shipped:

**File Created:** `sub_agents/base_agent_simple.py`
**Replaced:** `sub_agents/base_agent.py` (backed up to `base_agent_advanced.py.backup`)

### Working Components:
- âœ… Simplified BaseSubAgent
- âœ… All MCP servers (docker, homeassistant, web_search, github)
- âœ… AutonomousRouter (routes tasks to agents)
- âœ… AutonomousOrchestrator (coordinates execution)
- âœ… DockerAgent, ConfigAgent, ConsultingAgent (all working!)

### Test Results:
```bash
$ python autonomous_orchestrator.py "what docker containers are running?"
âœ… SUCCESS - Orchestrator ran autonomously!
```

**Build time:** ~1 hour
**Lines of code:** ~350 (simplified agent)
**Removed:** ~500 lines of non-existent advanced features
**Result:** WORKING autonomous system

---

## Phase 2: Advanced Features (Incremental)

Add one feature per week, each as backward-compatible enhancement.

### Week 1-2: LLM Provider (Highest Priority)

**File to create:** `llm_provider.py`

**Purpose:** Pluggable LLM backend with auto-detection

**Features:**
- Auto-detect Claude vs Ollama based on `ANTHROPIC_API_KEY`
- Unified interface for all LLMs
- Cost estimation per model
- Token counting

**Implementation:**
```python
class LLMProvider(ABC):
    @abstractmethod
    def generate(self, messages: List) -> str:
        pass

    @abstractmethod
    def estimate_tokens(self, text: str) -> int:
        pass

    @abstractmethod
    def get_cost_per_1k_tokens(self) -> Dict[str, float]:
        pass

class OllamaProvider(LLMProvider):
    # Free, local

class AnthropicProvider(LLMProvider):
    # Claude API

class OpenAIProvider(LLMProvider):
    # GPT API

def create_llm_provider(provider_type: str = "auto", **kwargs) -> LLMProvider:
    if provider_type == "auto":
        # Auto-detect based on env vars
        if os.getenv("ANTHROPIC_API_KEY"):
            return AnthropicProvider()
        else:
            return OllamaProvider()
```

**Integration:**
```python
# In base_agent_simple.py
from llm_provider import create_llm_provider

class BaseSubAgent:
    def __init__(self, ...):
        self.llm_provider = create_llm_provider("auto")
        self.llm = self.llm_provider.get_llm()  # Backward compatible
```

**Estimated time:** 2-3 hours
**Value:** High - enables production Claude + dev Ollama

---

### Week 3-4: Output Sanitizer (Security)

**File to create:** `output_sanitizer.py`

**Purpose:** Remove secrets from logs and outputs

**Features:**
- Regex-based secret detection (API keys, passwords, tokens)
- Redaction system (replace with `***REDACTED***`)
- Safe logging
- Configurable patterns

**Implementation:**
```python
class OutputSanitizer:
    PATTERNS = [
        r'(api[_-]?key\s*[:=]\s*["\']?)([a-zA-Z0-9_\-]{20,})',
        r'(password\s*[:=]\s*["\']?)([^\s"\']{8,})',
        r'(token\s*[:=]\s*["\']?)([a-zA-Z0-9_\-]{20,})',
        r'ghp_[a-zA-Z0-9]{36}',  # GitHub tokens
        # Add more patterns
    ]

    def sanitize(self, text: str) -> SanitizationResult:
        redacted = text
        redactions = []

        for pattern in self.PATTERNS:
            matches = re.finditer(pattern, text)
            for match in matches:
                secret = match.group(2) if len(match.groups()) > 1 else match.group(0)
                redacted = redacted.replace(secret, "***REDACTED***")
                redactions.append({
                    "type": self._detect_secret_type(pattern),
                    "position": match.span()
                })

        return SanitizationResult(
            sanitized_content=redacted,
            redactions=redactions,
            has_secrets=len(redactions) > 0
        )
```

**Integration:**
```python
# In base_agent_simple.py
from output_sanitizer import get_sanitizer

class BaseSubAgent:
    def __init__(self, ...):
        self.sanitizer = get_sanitizer()

    def _execute_tool(self, ...):
        result = tool(*args, **kwargs)
        # Sanitize before logging
        sanitized = self.sanitizer.sanitize(str(result))
        return sanitized
```

**Estimated time:** 1-2 hours
**Value:** High - prevents credential leaks

---

### Week 5: Cost Tracker (Budget Control)

**File to create:** `cost_tracker.py`

**Purpose:** Track API costs and prevent budget overruns

**Features:**
- Usage tracking (input/output tokens)
- Cost calculation per model
- Budget limits (daily, monthly)
- Alerts when approaching limits

**Implementation:**
```python
class CostTracker:
    def __init__(self, cost_per_1k_input: float, cost_per_1k_output: float):
        self.cost_per_1k_input = cost_per_1k_input
        self.cost_per_1k_output = cost_per_1k_output
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self.daily_limit = None
        self.monthly_limit = None

    def record_usage(self, input_tokens: int, output_tokens: int, operation: str):
        self.total_input_tokens += input_tokens
        self.total_output_tokens += output_tokens

        # Calculate cost
        cost = (
            (input_tokens / 1000) * self.cost_per_1k_input +
            (output_tokens / 1000) * self.cost_per_1k_output
        )

        # Check limits
        if self.daily_limit and self.get_today_cost() > self.daily_limit:
            raise CostLimit("Daily cost limit exceeded")

    def get_total_cost(self) -> float:
        return (
            (self.total_input_tokens / 1000) * self.cost_per_1k_input +
            (self.total_output_tokens / 1000) * self.cost_per_1k_output
        )
```

**Integration:**
```python
# In base_agent_simple.py
from cost_tracker import get_cost_tracker

class BaseSubAgent:
    def __init__(self, ...):
        costs = self.llm_provider.get_cost_per_1k_tokens()
        self.cost_tracker = get_cost_tracker(
            cost_per_1k_input=costs["input"],
            cost_per_1k_output=costs["output"]
        )
```

**Estimated time:** 1 hour
**Value:** Medium - prevents unexpected bills

---

### Week 6: Context Manager (Token Management)

**File to create:** `context_manager.py`

**Purpose:** Manage context window, truncate when needed

**Features:**
- Token counting
- Sliding window (keep recent + important)
- Context truncation strategies
- Compression

**Implementation:**
```python
class ContextManager:
    def __init__(self, max_tokens: int = 8000):
        self.max_tokens = max_tokens
        self.messages = []

    def add_message(self, message: BaseMessage):
        self.messages.append(message)

        # Truncate if needed
        while self._count_tokens() > self.max_tokens:
            self._truncate()

    def _truncate(self):
        # Strategy: Keep system message + last N messages
        if len(self.messages) > 2:
            # Remove oldest user/assistant message (keep system)
            self.messages.pop(1)

    def _count_tokens(self) -> int:
        # Rough estimation: ~4 chars per token
        total_chars = sum(len(str(m)) for m in self.messages)
        return total_chars // 4

    def get_messages(self) -> List[BaseMessage]:
        return self.messages
```

**Estimated time:** 1-2 hours
**Value:** Medium - prevents token limit errors

---

### Week 7-8: Dynamic Tool Registry (Extensibility)

**File to create:** `dynamic_tool_registry.py`

**Purpose:** Auto-discover and register tools

**Features:**
- Scan `mcp_servers/` directory
- Auto-import tool modules
- Hot-reload (add tools without restart)
- Registration API

**Implementation:**
```python
class DynamicToolRegistry:
    def __init__(self):
        self.tools = {}
        self.tool_metadata = {}

    def discover_tools(self, directory: str = "mcp_servers"):
        # Scan directory for *_tools.py files
        for file in os.listdir(directory):
            if file.endswith("_tools.py") and file != "__init__.py":
                module_name = file[:-3]
                self._load_tool_module(module_name)

    def _load_tool_module(self, module_name: str):
        # Dynamic import
        module = importlib.import_module(f"mcp_servers.{module_name}")

        # Extract functions
        for name, obj in inspect.getmembers(module):
            if callable(obj) and not name.startswith("_"):
                self.tools[name] = obj
                self.tool_metadata[name] = {
                    "module": module_name,
                    "doc": obj.__doc__
                }

    def register_tool(self, name: str, func: callable):
        self.tools[name] = func

    def get_tool(self, name: str):
        return self.tools.get(name)
```

**Estimated time:** 2-3 hours
**Value:** High - makes adding tools trivial

---

### Week 9: Emergency Stop (Safety)

**File to create:** `emergency_stop.py`

**Purpose:** Kill switch for runaway agents

**Features:**
- Global stop flag
- Check before each tool execution
- Exception handling
- Graceful shutdown

**Implementation:**
```python
class EmergencyStop:
    def __init__(self):
        self._stopped = False
        self._stop_file = Path(".emergency_stop")

    def trigger(self, reason: str):
        self._stopped = True
        self._stop_file.write_text(reason)
        raise EmergencyStopException(f"Emergency stop triggered: {reason}")

    def check_and_raise(self):
        # Check file-based stop (allows external triggering)
        if self._stop_file.exists():
            reason = self._stop_file.read_text()
            self._stopped = True
            raise EmergencyStopException(f"Emergency stop: {reason}")

        if self._stopped:
            raise EmergencyStopException("Emergency stop active")

    def reset(self):
        self._stopped = False
        if self._stop_file.exists():
            self._stop_file.unlink()
```

**Usage:**
```bash
# From terminal, stop all agents:
echo "User requested stop" > .emergency_stop

# Agents check before each tool:
self.emergency_stop.check_and_raise()
```

**Estimated time:** 30 minutes
**Value:** High - critical safety feature

---

## Phase 3: Self-Evolution (Months 2-3)

After Phase 2 features are stable, add:

### ToolsmithAgent
- Detects missing tools
- Generates MCP server code
- Requests approval
- Hot-reloads new tools

### MetaAgent Enhancements
- Tool discovery
- Self-extension
- Learning from failures

### Advanced Governance
- Multi-level approval workflows
- Risk assessment
- Audit logging

---

## Migration Path

### For Each Feature:

1. **Week N Day 1-2:** Implement module
2. **Week N Day 3:** Add tests
3. **Week N Day 4:** Integrate into `base_agent_simple.py`
4. **Week N Day 5:** Test with real agents
5. **Week N Day 6-7:** Documentation + examples

### Backward Compatibility:

```python
# base_agent_simple.py evolves to:
class BaseSubAgent:
    def __init__(self, agent_name: str, system_prompt: str, **kwargs):
        # Phase 1 (current)
        self.llm = ChatOllama(...)

        # Phase 2.1 (optional LLM provider)
        if "llm_provider" in kwargs:
            self.llm_provider = kwargs["llm_provider"]
            self.llm = self.llm_provider.get_llm()

        # Phase 2.2 (optional sanitizer)
        if "sanitizer" in kwargs:
            self.sanitizer = kwargs["sanitizer"]
        elif "use_sanitizer" not in kwargs or kwargs["use_sanitizer"]:
            from output_sanitizer import get_sanitizer
            self.sanitizer = get_sanitizer()
```

**Key principle:** Old agents keep working, new agents get features.

---

## Success Metrics

### Phase 1 (Complete):
- âœ… Orchestrator runs
- âœ… Sub-agents work
- âœ… Tools execute
- âœ… Can build new agents

### Phase 2 Goals:
- âœ… 90% cost reduction (Ollama dev, Claude prod)
- âœ… Zero credential leaks (sanitizer)
- âœ… Zero budget overruns (cost tracker)
- âœ… 50% faster tool addition (dynamic registry)
- âœ… 100% safety (emergency stop)

### Phase 3 Goals:
- âœ… Self-generates tools
- âœ… Learns from mistakes
- âœ… Full autonomy Level 4

---

## Current State

```
Phase 1: âœ… COMPLETE (ai-brain works NOW)
â”œâ”€â”€ base_agent_simple.py âœ…
â”œâ”€â”€ autonomous_router.py âœ…
â”œâ”€â”€ autonomous_orchestrator.py âœ…
â””â”€â”€ All sub-agents working âœ…

Phase 2: â­ï¸ READY TO START
â”œâ”€â”€ Week 1-2: llm_provider.py
â”œâ”€â”€ Week 3-4: output_sanitizer.py
â”œâ”€â”€ Week 5: cost_tracker.py
â”œâ”€â”€ Week 6: context_manager.py
â”œâ”€â”€ Week 7-8: dynamic_tool_registry.py
â””â”€â”€ Week 9: emergency_stop.py

Phase 3: ğŸ“‹ PLANNED
â”œâ”€â”€ ToolsmithAgent
â”œâ”€â”€ MetaAgent evolution
â””â”€â”€ Advanced governance
```

---

## Next Steps

### This Week:
1. âœ… **DONE:** Create working base agent
2. âœ… **DONE:** Test orchestrator
3. â­ï¸ **TODO:** Package as pip installable
4. â­ï¸ **TODO:** Build first production agent

### Next Week:
1. Start Phase 2.1: Build `llm_provider.py`
2. Integrate auto-detection
3. Test with Claude + Ollama
4. Update documentation

### This Month:
- Complete Phase 2.1-2.3
- Ship 3 production agents
- Validate incremental approach
- Gather feedback

---

## Files Modified (Phase 1)

- âœ… Created: `sub_agents/base_agent_simple.py`
- âœ… Replaced: `sub_agents/base_agent.py` (now simplified)
- âœ… Backed up: `sub_agents/base_agent_advanced.py.backup`
- âœ… Modified: `autonomous_router.py` (gemma3:4b instead of llama3.1)

---

## Conclusion

**Phase 1 Success:** ai-brain NOW WORKS!

**Strategy validated:** Ship working core, add features incrementally

**Timeline:**
- Phase 1: 1 hour âœ…
- Phase 2: 9 weeks (1 feature/week) â­ï¸
- Phase 3: 2-3 months ğŸ“‹

**Result:** Working autonomous system TODAY + continuous improvement

The hybrid approach works. Let's ship it.
