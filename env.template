# ============================================================================
# Close-to-Zero Prompting AI Brain - Environment Variables Template
# ============================================================================
# Copy this file to .env and fill in your actual values:
#   cp env.template .env
# Then edit .env with your API keys and tokens
# ============================================================================

# ----------------------------------------------------------------------------
# LLM Provider Configuration
# ----------------------------------------------------------------------------
# Choose your LLM provider: ollama (default, free, local), openai, or anthropic
AI_BRAIN_LLM_PROVIDER=ollama

# Model name (varies by provider)
# Ollama: gemma3:4b, llama3, mistral, etc.
# OpenAI: gpt-4, gpt-4-turbo, gpt-3.5-turbo
# Anthropic: claude-3-sonnet-20240229, claude-3-opus-20240229
AI_BRAIN_LLM_MODEL=gemma3:4b

# LLM temperature (0.0-1.0, default: 0.7)
AI_BRAIN_LLM_TEMPERATURE=0.7

# ----------------------------------------------------------------------------
# System Configuration
# ----------------------------------------------------------------------------
# Environment: dev (auto-approve yellow), staging, or production (requires approval)
AI_BRAIN_ENVIRONMENT=production

# Maximum retries for failed operations
AI_BRAIN_MAX_RETRIES=5

# Timeout for operations in seconds
AI_BRAIN_TIMEOUT=30

# ----------------------------------------------------------------------------
# LLM Provider API Keys
# ----------------------------------------------------------------------------
# OpenAI API Key (if using OpenAI provider)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Anthropic API Key (if using Anthropic provider)
# Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# ----------------------------------------------------------------------------
# Web Search API Keys (choose one)
# ----------------------------------------------------------------------------
# Tavily AI (recommended) - Get from: https://tavily.com
TAVILY_API_KEY=

# OR Serper.dev (alternative) - Get from: https://serper.dev
SERPER_API_KEY=

# ----------------------------------------------------------------------------
# Home Assistant Integration
# ----------------------------------------------------------------------------
# Home Assistant Long-Lived Access Token
# Create at: http://your-ha-instance:8123/profile -> Long-Lived Access Tokens
HA_TOKEN=

# Home Assistant Base URL (optional, defaults to http://localhost:8123)
HA_BASE_URL=http://localhost:8123

# ----------------------------------------------------------------------------
# Notes
# ----------------------------------------------------------------------------
# 1. For local development with Ollama (free, private):
#    - Set AI_BRAIN_LLM_PROVIDER=ollama
#    - No API keys needed
#    - Make sure Ollama is running: ollama serve
#
# 2. For production with commercial LLMs:
#    - Set AI_BRAIN_LLM_PROVIDER=openai or anthropic
#    - Add corresponding API key above
#
# 3. Web search is optional but recommended for current information
#    - Choose either Tavily or Serper
#    - Tavily is recommended (better results)
#
# 4. Home Assistant integration is optional
#    - Only needed if using Home Assistant tools
#
# 5. Never commit .env file to git (it's in .gitignore)

